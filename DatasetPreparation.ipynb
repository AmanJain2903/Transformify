{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePath = 'Dataset/png_images/IMAGES/'\n",
    "maskPath = 'Dataset/png_masks/MASKS/'\n",
    "\n",
    "valImagePath = 'ValDataset/png_images/IMAGES/'\n",
    "valMaskPath = 'ValDataset/png_masks/MASKS/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in os.listdir(maskPath):\n",
    "    initPath = maskPath + image\n",
    "    renamedPath = maskPath + 'img' + image[3:]\n",
    "    os.rename(initPath, renamedPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir ValDataset/\n",
    "! mkdir ValDataset/png_images/\n",
    "! mkdir ValDataset/png_masks/\n",
    "! mkdir ValDataset/png_images/IMAGES/\n",
    "! mkdir ValDataset/png_masks/MASKS/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "valList=[\"0115\",\"0025\",\"0010\",\"0003\",\"0125\",\"0200\",\"0515\",\"0225\",\"0805\",\"0915\",\"0630\",\"0301\",\"0112\",\"0905\",\"0823\",\"0527\",\"0088\",\"0055\",\"0018\",\n",
    "          \"0222\",\"0049\",\"0273\",\"0299\",\"0282\",\"0372\",\"0027\",\"0445\",\"0582\",\"0374\",\"0956\",\"0211\",\"0019\",\"0961\",\"0397\",\"0699\",\"0789\",\"0996\",\"0290\",\n",
    "          \"0110\",\"0315\",\"0335\",\"0419\",\"0666\",\"0525\",\"0927\",\"0555\",\"0275\",\"0855\",\"0815\",\"0130\",\"0371\",\"0412\",\"0105\",\"0423\",\"0507\",\"0028\",\"0035\",\"0118\",\n",
    "          \"0232\",\"0849\",\"0673\",\"0688\",\"0777\",\"0472\",\"0991\",\"0485\",\"0592\",\"0334\",\"0827\",\"0651\",\"0619\",\"0567\",\"0393\",\"0609\",\"0719\",\"0916\",\"0190\",\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in valList:\n",
    "    initPath = imagePath + 'img_' + name + '.png'\n",
    "    finalPath = valImagePath + 'img_' + name + '.png'\n",
    "    shutil.move(initPath, finalPath)\n",
    "    \n",
    "    initPath = maskPath + 'img_' + name + '.png'\n",
    "    finalPath = valMaskPath + 'img_' + name + '.png'\n",
    "    shutil.move(initPath, finalPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-08 23:22:56.555308: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Pro\n",
      "2025-02-08 23:22:56.555479: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 18.00 GB\n",
      "2025-02-08 23:22:56.555484: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 6.00 GB\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1739085776.555805 10627753 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1739085776.555940 10627753 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "trainDataset = tf.data.Dataset.from_tensor_slices(\n",
    "    ([imagePath+i for i in os.listdir(imagePath)],\n",
    "    [maskPath+'img'+i[3:] for i in os.listdir(imagePath)])\n",
    ")\n",
    "\n",
    "valDataset = tf.data.Dataset.from_tensor_slices(\n",
    "    ([valImagePath+i for i in os.listdir(valImagePath)],\n",
    "    [valMaskPath+'img'+i[3:] for i in os.listdir(valImagePath)])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'Dataset/png_images/IMAGES/img_0564.png'>, <tf.Tensor: shape=(), dtype=string, numpy=b'Dataset/png_masks/MASKS/img_0564.png'>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'ValDataset/png_images/IMAGES/img_0996.png'>, <tf.Tensor: shape=(), dtype=string, numpy=b'ValDataset/png_masks/MASKS/img_0996.png'>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-08 23:23:06.180332: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-02-08 23:23:06.183025: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for i in trainDataset.take(1):\n",
    "    print(i)\n",
    "for i in valDataset.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(923, 77)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainDataset), len(valDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#         R        G       B\n",
    "MEAN = [123.675, 116.28, 103.53]\n",
    "STD = [58.395, 57.12, 57.375]\n",
    "\n",
    "# These Values Were Obtained From The ImageNet Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcess(imagePath, maskPath):\n",
    "    image = tf.io.read_file(imagePath)\n",
    "    image = tf.image.decode_jpeg(image)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image - MEAN) / STD\n",
    "\n",
    "    mask = tf.io.read_file(maskPath)\n",
    "    mask = tf.image.decode_jpeg(mask)\n",
    "    mask = tf.squeeze(mask, axis=-1)\n",
    "    mask = tf.cast(mask, tf.float32)\n",
    "    \n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepTrainDataset = trainDataset.map(preProcess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "prepValDataset = valDataset.map(preProcess, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(825, 550, 3)\n",
      "(825, 550)\n"
     ]
    }
   ],
   "source": [
    "for i, j in prepTrainDataset.take(1):\n",
    "    print(i.shape)\n",
    "    print(j.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation Using Albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "H,W = 512,512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8v/j561wc497p1672n3xvshbbd00000gn/T/ipykernel_22730/1788790855.py:8: UserWarning: Argument(s) 'num_shadows_lower, num_shadows_upper' are not valid for transform RandomShadow\n",
      "  A.RandomShadow (shadow_roi=(0, 0.5, 1, 1),\n"
     ]
    }
   ],
   "source": [
    "transform = A.Compose([\n",
    "    A.RandomCrop (H,W, p=1.0),\n",
    "    A.HorizontalFlip(p=0.3),\n",
    "    A.VerticalFlip(p=0.3),\n",
    "    A.RandomRotate90(p=0.3),\n",
    "    A.Transpose(p=0.3),\n",
    "    A.Sharpen (alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=0.1),\n",
    "    A.RandomShadow (shadow_roi=(0, 0.5, 1, 1),\n",
    "                    num_shadows_lower=1, num_shadows_upper=2,\n",
    "                    shadow_dimension=5, p=0.1),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    #A.Resize(H,W),\n",
    "])\n",
    "\n",
    "valTransform = A.Compose([\n",
    "    A.Resize(H, W),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augAlbument(image, mask):\n",
    "    augmented = transform(image=image, mask=mask)\n",
    "    \n",
    "    return [tf.convert_to_tensor(augmented['image'], dtype=tf.float32), \n",
    "            tf.convert_to_tensor(augmented['mask'], dtype=tf.float32)]\n",
    "\n",
    "def valAugAlbument(image, mask):\n",
    "    augmented = valTransform(image=image, mask=mask)\n",
    "    \n",
    "    return [tf.convert_to_tensor(augmented['image'], dtype=tf.float32), \n",
    "            tf.convert_to_tensor(augmented['mask'], dtype=tf.float32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(image, mask):\n",
    "    augmentedOutput = tf.numpy_function(augAlbument, [image, mask], [tf.float32, tf.float32])\n",
    "    return {'pixel_values': tf.transpose(augmentedOutput[0], (2, 0, 1)), 'labels': augmentedOutput[1]}\n",
    "\n",
    "def valAugment(image, mask):\n",
    "    augmentedOutput = tf.numpy_function(valAugAlbument, [image, mask], [tf.float32, tf.float32])\n",
    "    return {'pixel_values': tf.transpose(augmentedOutput[0], (2, 0, 1)), 'labels': augmentedOutput[1]}\n",
    "\n",
    "# Transpose Explained\n",
    "# The Transpose Function Is Used To Rearrange The Dimensions Of The Image Tensor from (H,W,C) To (C,H,W)\n",
    "# h, w, c      ->        c, h, w\n",
    "# 0, 1, 2      ->        2, 0, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "trainDataset = (\n",
    "    prepTrainDataset\n",
    "    .shuffle(10)\n",
    "    .map(augment,num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "valDataset = (\n",
    "    prepValDataset\n",
    "    .map(valAugment,num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 512, 512)\n",
      "(2, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-08 23:27:38.678980: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for i in trainDataset.take(1):\n",
    "    print(i['pixel_values'].shape)\n",
    "    print(i['labels'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset.save('SavedDataset/trainDataset')\n",
    "valDataset.save('SavedDataset/valDataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Size: 3692.04 MB\n",
      "Validation Dataset Size: 308.00 MB\n"
     ]
    }
   ],
   "source": [
    "def getFolderSize(folderPath):\n",
    "    totalSize = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(folderPath):\n",
    "        for filename in filenames:\n",
    "            filePath = os.path.join(dirpath, filename)\n",
    "            totalSize += os.path.getsize(filePath)\n",
    "    return totalSize  # Size in bytes\n",
    "trainSizeInBytes = getFolderSize(\"SavedDataset/trainDataset\")\n",
    "valSizeInBytes = getFolderSize(\"SavedDataset/valDataset\")\n",
    "print(f\"Train Dataset Size: {trainSizeInBytes / (1024 * 1024):.2f} MB\")\n",
    "print(f\"Validation Dataset Size: {valSizeInBytes / (1024 * 1024):.2f} MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ComputerVision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
